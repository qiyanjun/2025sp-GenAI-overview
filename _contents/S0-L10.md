---
layout: post
title: Platform - More agent related 
lecture: 
lectureVersion: next
extraContent: 
notes: more recent tools on LLM agent 
video: team-2
tags:
- 
desc: 2025-S4
term: 2025-seminarRead
categories:
- 
---


In this session, our readings cover: 

## Required Readings: 


![Image]({{ site.baseurl }}/Lectures/aitools.png)



#### Agent Tools/Libraries: 
+ [https://langchain-ai.github.io/langgraph/tutorials/introduction/](https://langchain-ai.github.io/langgraph/tutorials/introduction/)

+ [https://huggingface.co/docs/transformers/en/agents](https://huggingface.co/docs/transformers/en/agents)

+ [AutoGen](https://github.com/ag2ai/ag2?tab=readme-ov-file)

+ OpenAI Operator

OpenAI introduces Operator, a research preview of a browser-controlling agent available to Pro users in the U.S. Powered by the Computer-Using Agent (CUA) model, Operator can perform web-based tasks like filling forms, ordering groceries, and creating memes by interacting with graphical interfaces through typing, clicking, and scrolling. The agent leverages GPT-4o's vision capabilities and reinforcement learning to navigate websites without requiring API integrations.

The system includes multiple safety features, including user takeover mode for sensitive information, task limitations, and defenses against malicious websites. OpenAI is partnering with companies like DoorDash, Instacart, and Uber to refine the technology, while also exploring public sector applications. Future plans include releasing CUA through an API, enhancing capabilities, and expanding access to Plus, Team, and Enterprise users.

+ AutoGen v0.4

Introduces a cohesive AutoGen ecosystem that includes the framework, developer tools, and applications. The framework’s layered architecture clearly defines each layer’s functionality. It supports both first-party and third-party applications and extensions.
Microsoft Research announces AutoGen v0.4, a major update to their multi-agent AI framework. The new version introduces a complete redesign with an asynchronous, event-driven architecture that improves code quality, robustness, and scalability. Key features include modular components, built-in debugging tools, cross-language support, and enhanced observability through OpenTelemetry integration.

The update brings a new three-layered framework architecture consisting of core building blocks, AgentChat API, and extensions. It also introduces improved developer tools including AutoGen Bench for performance testing, an upgraded AutoGen Studio with real-time agent updates and visual team building, and Magentic-One, a new generalist multi-agent application for handling web and file-based tasks. The release maintains backward compatibility through the AgentChat API, making the migration from v0.2 straightforward while adding new capabilities like streaming messages and improved task progress management.

+  https://docs.ag2.ai/docs/blog/2025-02-13-DeepResearchAgent/index


#### one Survey Blogpost on agent2024 ...

+ https://open.substack.com/pub/victordibia/p/ai-agents-2024-rewind-a-year-of-building?r=ya7nu&utm_medium=ios


#### Iterative Refinement of Project-Level Code Context for Precise Code Generation with Compiler Feedback
+ [Submitted on 25 Mar 2024 (v1), last revised 11 Jun 2024 (this version, v3)]
+ Zhangqian Bi, Yao Wan, Zheng Wang, Hongyu Zhang, Batu Guan, Fangxin Lu, Zili Zhang, Yulei Sui, Hai Jin, Xuanhua Shi
+ Large Language Models (LLMs) have shown remarkable progress in automated code generation. Yet, LLM-generated code may contain errors in API usage, class, data structure, or missing project-specific information. As much of this project-specific context cannot fit into the prompts of LLMs, we must find ways to allow the model to explore the project-level code context. We present CoCoGen, a new code generation approach that uses compiler feedback to improve the LLM-generated code. CoCoGen first leverages static analysis to identify mismatches between the generated code and the project's context. It then iteratively aligns and fixes the identified errors using information extracted from the code repository. We integrate CoCoGen with two representative LLMs, i.e., GPT-3.5-Turbo and Code Llama (13B), and apply it to Python code generation. Experimental results show that CoCoGen significantly improves the vanilla LLMs by over 80% in generating code dependent on the project context and consistently outperforms the existing retrieval-based code generation baselines.



## More Readings: 

