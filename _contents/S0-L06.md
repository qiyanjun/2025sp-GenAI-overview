---
layout: post
title:  advanced LLM - Math reasoning 
lecture: 
lectureVersion: next
extraContent: 
notes: team-4
video: team-4
tags:
- 
desc: 2025-S4
term: 2025-seminarRead
categories:
- 
---


In this session, our readings cover: 

## Required Readings: 


#### Large Language Models for Mathematical Reasoning: Progresses and Challenges
+ Janice Ahn, Rishu Verma, Renze Lou, Di Liu, Rui Zhang, Wenpeng Yin
+ [Submitted on 31 Jan 2024 (v1), last revised 16 Sep 2024 (this version, v4)]
+ Mathematical reasoning serves as a cornerstone for assessing the fundamental cognitive capabilities of human intelligence. In recent times, there has been a notable surge in the development of Large Language Models (LLMs) geared towards the automated resolution of mathematical problems. However, the landscape of mathematical problem types is vast and varied, with LLM-oriented techniques undergoing evaluation across diverse datasets and settings. This diversity makes it challenging to discern the true advancements and obstacles within this burgeoning field. This survey endeavors to address four pivotal dimensions: i) a comprehensive exploration of the various mathematical problems and their corresponding datasets that have been investigated; ii) an examination of the spectrum of LLM-oriented techniques that have been proposed for mathematical problem-solving; iii) an overview of factors and concerns affecting LLMs in solving math; and iv) an elucidation of the persisting challenges within this domain. To the best of our knowledge, this survey stands as one of the first extensive examinations of the landscape of LLMs in the realm of mathematics, providing a holistic perspective on the current state, accomplishments, and future challenges in this rapidly evolving field.

#### A Survey of Deep Learning for Mathematical Reasoning
+ Pan Lu, Liang Qiu, Wenhao Yu, Sean Welleck, Kai-Wei Chang
+ [Submitted on 20 Dec 2022 (v1), last revised 22 Jun 2023 (this version, v2)]
+ Mathematical reasoning is a fundamental aspect of human intelligence and is applicable in various fields, including science, engineering, finance, and everyday life. The development of artificial intelligence (AI) systems capable of solving math problems and proving theorems has garnered significant interest in the fields of machine learning and natural language processing. For example, mathematics serves as a testbed for aspects of reasoning that are challenging for powerful deep learning models, driving new algorithmic and modeling advances. On the other hand, recent advances in large-scale neural language models have opened up new benchmarks and opportunities to use deep learning for mathematical reasoning. In this survey paper, we review the key tasks, datasets, and methods at the intersection of mathematical reasoning and deep learning over the past decade. We also evaluate existing benchmarks and methods, and discuss future research directions in this domain.




#### DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models
+ Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, Y.K. Li, Y. Wu, Daya Guo
+ Mathematical reasoning poses a significant challenge for language models due to its complex and structured nature. In this paper, we introduce DeepSeekMath 7B, which continues pre-training DeepSeek-Coder-Base-v1.5 7B with 120B math-related tokens sourced from Common Crawl, together with natural language and code data. DeepSeekMath 7B has achieved an impressive score of 51.7% on the competition-level MATH benchmark without relying on external toolkits and voting techniques, approaching the performance level of Gemini-Ultra and GPT-4. Self-consistency over 64 samples from DeepSeekMath 7B achieves 60.9% on MATH. The mathematical reasoning capability of DeepSeekMath is attributed to two key factors: First, we harness the significant potential of publicly available web data through a meticulously engineered data selection pipeline. Second, we introduce Group Relative Policy Optimization (GRPO), a variant of Proximal Policy Optimization (PPO), that enhances mathematical reasoning abilities while concurrently optimizing the memory usage of PPO.
+ Elements: 
  - Both Deepseek and Qwen use GRPO in post-training! Group Relative Policy Optimization or GRPO was introduced in the DeepSeekMath Paper last year to improve mathematical reasoning capabilities with less memory consumption, but is now used in an online way also to improve Truthfulness, Helpfulness, Conciseness… 
  - Generate multiple outputs for each input question using the current Policy
  - Score these outputs using a reward model
  - Average the rewards and use it as a baseline to compute the advantages
  - Update the Policy to maximize the GRPO objective, which includes the advantages and a KL term
+ Insights: 
  - Doesn’t need value function model, reducing memory and complexity
  - Adds KL term directly to the loss rather than in the reward
  - Works with rule-based Reward Models and Generative/Score based RM
  - Looks similar to RLOO method
  - DS 3 improved coding, math, writing, role-playing, and question answering
  



#### DeepSeek-V3 Technical Report
+ DeepSeek-AI, (100 additional authors not shown)
+ We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token. To achieve efficient inference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architectures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms other open-source models and achieves performance comparable to leading closed-source models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours for its full training. In addition, its training process is remarkably stable. Throughout the entire training process, we did not experience any irrecoverable loss spikes or perform any rollbacks. The model checkpoints are available at this https URL.






## More Readings: 




#### AI Capabilities Can Be Significantly Improved Without Expensive Retraining
+ https://epoch.ai/blog/ai-capabilities-can-be-significantly-improved-without-expensive-retraining
